{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "data_path = 'train_data'\n",
    "train_data = []\n",
    "labels = []\n",
    "for file in os.listdir(data_path):\n",
    "    # 获取文件的绝对路径\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    # 截取文件名\n",
    "    label = file.split('_')[-1]\n",
    "    # 检查文件是否是目录\n",
    "    if os.path.isdir(file_path):\n",
    "        for data in os.listdir(file_path):\n",
    "            # 读取文件内容\n",
    "            a = np.load(os.path.join(file_path, data))\n",
    "            train_data.append(a)\n",
    "            labels.append(int(label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4000, 1, 734, 80])\n"
     ]
    }
   ],
   "source": [
    "length = [i.shape[0] for i in train_data]\n",
    "width = [i.shape[1] for i in train_data]\n",
    "max_length = max(length)\n",
    "width = max(width)\n",
    "\n",
    "# 将所有数据填充到最大长度\n",
    "for i in range(len(train_data)):\n",
    "    if train_data[i].shape[0] < max_length:\n",
    "        train_data[i] = np.vstack((train_data[i], np.zeros((max_length - train_data[i].shape[0], width))))\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# 将数据和标签转换为张量\n",
    "train_data_tensor = torch.tensor(train_data).unsqueeze(1).float()\n",
    "print(train_data_tensor.shape)\n",
    "labels_tensor = torch.tensor(labels).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述代码获取了数据的最大长度，并将所有数据扩充至最大长度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建神经网络\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# 定义网络\n",
    "# 该网络输入为一个data序列，输出为该序列的labels分类\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (3, 3))\n",
    "        self.conv2 = nn.Conv2d(32, 64, (3, 3))\n",
    "        self.conv3 = nn.Conv2d(64, 128, (3, 3))\n",
    "        self.fc1 = nn.Linear(90 * 8 * 128, 128)  \n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # print('-' * 20)\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 90 * 8 * 128)\n",
    "        x = self.dropout(x) \n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.训练数据并输出准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([4000, 1, 734, 80])\n",
      "Labels shape: torch.Size([4000])\n",
      "[1,    10] loss: 1.740\n",
      "[1,    20] loss: 0.677\n",
      "[1,    30] loss: 0.672\n",
      "[1,    40] loss: 0.667\n",
      "[1,    50] loss: 0.655\n",
      "[1,    60] loss: 0.619\n",
      "[1,    70] loss: 0.659\n",
      "[1,    80] loss: 0.634\n",
      "[1,    90] loss: 0.627\n",
      "[1,   100] loss: 0.624\n",
      "[2,    10] loss: 0.623\n",
      "[2,    20] loss: 0.598\n",
      "[2,    30] loss: 0.616\n",
      "[2,    40] loss: 0.594\n",
      "[2,    50] loss: 0.564\n",
      "[2,    60] loss: 0.578\n",
      "[2,    70] loss: 0.543\n",
      "[2,    80] loss: 0.521\n",
      "[2,    90] loss: 0.529\n"
     ]
    }
   ],
   "source": [
    "# 利用torch.utils.data构建数据集\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "print(\"Data shape:\", train_data_tensor.shape)\n",
    "print(\"Labels shape:\", labels_tensor.shape)\n",
    "# 创建 TensorDataset 对象\n",
    "dataset = TensorDataset(train_data_tensor, labels_tensor)\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "\n",
    "# 创建 DataLoader 对象\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "net = Model()  \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 训练网络\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        # print(inputs.shape)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "# 保存模型\n",
    "torch.save(net.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "net = Model()\n",
    "net.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证网络的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 1, 734, 80])\n"
     ]
    }
   ],
   "source": [
    "# 构建测试集\n",
    "result_data_path = 'test_data'\n",
    "result_data = []\n",
    "result_labels = []\n",
    "for file in os.listdir(result_data_path):\n",
    "    a = np.load(os.path.join(result_data_path, file))\n",
    "    result_data.append(a)\n",
    "    result_labels.append(-1)\n",
    "\n",
    "# 截断或补全到 max_length x width\n",
    "for i in range(len(result_data)):\n",
    "    if result_data[i].shape[0] < max_length:\n",
    "        result_data[i] = np.vstack((result_data[i], np.zeros((max_length - result_data[i].shape[0], width))))\n",
    "    elif result_data[i].shape[0] > max_length:\n",
    "        result_data[i] = result_data[i][:max_length, :]\n",
    "\n",
    "result_data = np.array(result_data)\n",
    "result_labels = np.array(result_labels)\n",
    "\n",
    "# 将数据和标签转换为张量\n",
    "result_data_tensor = torch.tensor(result_data).unsqueeze(1).float()\n",
    "print(result_data_tensor.shape)\n",
    "result_labels_tensor = torch.tensor(result_labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建预测集\n",
    "result_dataset = TensorDataset(result_data_tensor, result_labels_tensor)\n",
    "result_data_loader = DataLoader(result_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 测试网络\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for inputs, _ in result_data_loader:\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "result = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "# 将预测结果保存\n",
    "result['label'] = predictions\n",
    "result.to_csv('23210980049.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
